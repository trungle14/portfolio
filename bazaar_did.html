<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Folio Bootstrap Template - Blog Single</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Poppins:300,300i,400,400i,500,500i,600,600i,700,700i|Playfair+Display:400,400i,500,500i,600,600i,700,700i,900,900i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Folio
  * Updated: Jan 29 2024 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/folio-bootstrap-portfolio-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top header-inner-pages">
    <div class="container d-flex align-items-center justify-content-between">

      <a href="index.html" class="logo"><img src="assets/img/TRUNGLOGO.png" alt="" class="img-fluid"></a>
      <!-- Uncomment below if you prefer to use an text logo -->
      <!-- <h1 class="logo"><a href="index.html">Folio</a></h1> -->

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto " href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link  scrollto" href="#portfolio">Portfolio</a></li>
          <li><a class="nav-link active  scrollto" href="#journal">Blog</a></li>
          <li class="dropdown"><a href="#"><span>Drop Down</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="#">Drop Down 1</a></li>
              <li class="dropdown"><a href="#"><span>Deep Drop Down</span> <i class="bi bi-chevron-right"></i></a>
                <ul>
                  <li><a href="#">Deep Drop Down 1</a></li>
                  <li><a href="#">Deep Drop Down 2</a></li>
                  <li><a href="#">Deep Drop Down 3</a></li>
                  <li><a href="#">Deep Drop Down 4</a></li>
                  <li><a href="#">Deep Drop Down 5</a></li>
                </ul>
              </li>
              <li><a href="#">Drop Down 2</a></li>
              <li><a href="#">Drop Down 3</a></li>
              <li><a href="#">Drop Down 4</a></li>
            </ul>
          </li>
          <li><a class="nav-link scrollto" href="#contact">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Blog Single ======= -->
    <div class="main-content paddsection">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-md-8 col-md-offset-2">
            <div class="row">
              <div class="container-main single-main">
                <div class="col-md-12">
                  <div class="block-main mb-30">
                    <img src="assets/img/blog-post-big.jpg" class="img-responsive" alt="reviews2">
                    <div class="content-main single-post padDiv">
                      <div class="journal-txt">
                        <h4><a href="#">SO LETS MAKE THE MOST IS BEAUTIFUL</a></h4>
                      </div>
                      <div class="post-meta">
                        <ul class="list-unstyled mb-0">
                          <li class="author">by:<a href="#">Trung Le</a></li>
                          <li class="date">date:<a href="#">November 31, 2023</a></li>
                          <li class="commont"><i class="ion-ios-heart-outline"></i><a href="#">3 Comments</a></li>
                        </ul>
                      </div>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Document with GitHub Logo</title>
    <!-- Include FontAwesome -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css">
</head>
<body>
    <blockquote>
        Visit Github repository for full document of the project 
        <!-- Correct FontAwesome icon class -->
        <i class="fab fa-github"></i>
        <a href="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/tree/main" class="highlight-link">here</a>.
    </blockquote>
</body>
</html>

 <h1>Business Overview of Bazaar.com</h1>
    <p>Bazaar.com, a prominent online retailer in the United States, has established a significant presence in digital advertising, focusing on both display and search engine advertising, particularly in running paid search ads across platforms like Google and Bing. The company classifies its paid advertisements into two main categories: branded and non-branded keywords.</p>

    <h2>Introduction to the Difference in Difference (DiD) Approach</h2>
   <blockquote><p> Before diving into DiD, consider a hypothetical scenario involving Lionel Messi's transfer to FC Miami and its impact on Florida's tourism, as a way to understand the effect of significant sports events on tourism. 
     The DiD method is commonly used for assessing the impacts of large-scale policy changes or interventions by comparing the before and after effects of the intervention.</p>
   </blockquote>
    <h2>Challenges with Bob‚Äôs ROI Analysis</h2>
    <p>Bob, from Bazaar's marketing analytics team, calculated a 320% ROI from sponsored ads, raising concerns about the potential overestimation of the ads' effectiveness, as customers searching for 'Bazaar' might already be inclined to visit the website, thereby questioning the actual impact of branded keyword ads.</p>

    <h2>Defining Treatment and Control Groups</h2>
    <p>The experiment treats the stoppage of sponsored ads as a causal test, with Google serving as the treatment group (impacted by the outage) and Bing, Yahoo, and Ask as control groups (unaffected by the outage).</p>

    <h2>First Difference Estimate</h2>
    <p>The initial analysis focuses on the change in total web traffic following the ad outage. The log transformation of data addresses skewness, facilitating a more accurate model building process.</p>
    
    <div class="code-snippet">
        <!-- R code for First Difference Estimate -->
    
 <h4>R Code Snippet is highlight</h4> in  <code>this format </code><br>
    <code>
  setwd ("/Users/Trung/Downloads") <br>
data = read.csv('did_sponsored_ads.csv')<br>
treatment_week = c(10,11,12)<br>
data &lt;- data %&gt;% mutate(treatment = ifelse(platform == 'goog',1,0),<br>
                       after = ifelse(week %in% treatment_week,1,0),<br>
                       total_traffic = avg_spons + avg_org)<br>

google_Ad = data %&gt;% filter (platform=="goog")<br>
#Plotting the histogram for total clicks on Google<br>
hist(google_Ad$total_traffic)
        </code>
    </div>

                       
  
<h2>Define the Treatment and Control</h2><br>
   
As per this experiment, stoppage of sponsored ads serves as a way to test the causality, hence in our analysis (say in difference in differences we would be testing difference of change in Google click through ads vs other platforms ) Google would serve as treatment
group (as there was impact of outage here) and Bing , yahoo and ask would serve as control groups (as there was no impact of outage) 

<h2> Consider a First Difference Estimate</h2>

In our analytical approach, we focus on determining whether there's a significant change in total web traffic following the ad outage compared to the period before the outage. This comparison of pre- and post-outage data is crucial for gaining insights into the causal impact of the outage on website traffic. Given that the data is heavily skewed ‚Äî with 75% of the data showing fewer than 10,000 clicks ‚Äî we employ a log transformation. This transformation is a standard technique to normalize data, making it more suitable for model building. By using a log transform, we can mitigate the effects of the skewness in the data, leading to more reliable and interpretable analytical results

    <code>
# Try a simple pre-post estimator
# Simple pre-post estimator
google_data<- data %>% filter(platform == "goog")
model <- lm(log(total_traffic) ~ after, data = google_data)
summary(model)
    </code>

<b>Interpretation:</b>
The p-value of 0.998 suggests no significant insights from our test. While there appears to be a 13.06% increase in web traffic from Google, the high p-value indicates this is not statistically significant. Our current analysis, based on pre-post comparison within the treatment group, assumes constant market conditions, which might not hold true in scenarios like holiday seasons. To overcome these limitations, we propose using the Difference in Difference (DiD) method. DiD considers both treatment and control groups, offering a more reliable approach by accounting for external variations.


# Calculate the Difference-in-Differences

Prior to conducting a Difference-in-Differences analysis, it's crucial to verify the existence of parallel trends beforehand. This step ensures that the differences we're comparing are, in fact, meaningful. If there's already a decreasing trend between the differences, it would hinder our ability to derive accurate insights.   

<b>Visualization of parallel trend</b><br>
    <code>
temp1 = data %>%  filter(platform %in%  c('bing')) %>% select(week, total_traffic)
temp2 = data %>%  filter(platform %in%  c('yahoo')) %>% select(week, total_traffic)
temp3 = data %>%  filter(platform %in%  c('ask')) %>% select(week, total_traffic)

ggplot(data %>% filter(platform == 'goog'), aes(x=week, y= total_traffic, color = 'Google')) +
  geom_line() +
  geom_line(aes(x=week, y= total_traffic, color = 'Bing'), data = temp1) +<br>
  geom_line(aes(x=week, y= total_traffic, color = 'Yahoo'), data = temp2) +<br>
  geom_line(aes(x=week, y= total_traffic, color = 'Ask'), data = temp3) +<br>
  geom_vline(xintercept = 9,color='red') +<br>
  scale_y_continuous(sec.axis = sec_axis(~./6)) +<br>
  scale_x_continuous(breaks = seq(1, 12, by = 1)) +<br>
  labs(y = "Total Traffic", x = "Week") +<br>
  theme_bw() +<br>
  theme(legend.title = element_blank())
    </code><br>

<img width="630" alt="Screenshot 2024-01-25 at 23 12 03" src="https://github.com/trungle14/trungle14test/assets/143222481/696dd200-67a6-47ea-a569-d0cf7b1e0bfa">


The graph shows no parallel trends, but rather an increasing divergence until week 9, followed by a decrease in Google's click-through numbers compared to other platforms, indicating convergence. Therefore, while DiD analysis remains valuable, it requires cautious application and careful interpretation of the results.


    <code>
model_did <- lm(total_traffic ~ treatment + factor(week) + treatment * factor(week),data=data)
summary(model_did)
    </code>

Although our initial assumption was not confirmed, we proceeded with a Difference in Difference (DiD) regression between the treatment and control groups. This approach aims to estimate the actual causal impact of the sponsored ads. The key independent variables in the DiD regression are Treatment, After, and the Interaction between Treatment and After.

    <code>
did <- lm(total_traffic ~ treatment + after + treatment * after, data=data)
summary(did)
    </code>

By stopping sponsored ads on Google, Bazaar experiences an average loss of 9,910 clicks per week. This finding, derived from comparing the new treatment effect with the control group, highlights the causal influence of sponsored ads. This method is superior to the pre-post estimate because it allows us to analyze the behaviors of both control and treatment groups in a single model, adjusting for time-related variations and minimizing the impact of seasonality




  
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
<h2>üåü Image Classification - Cats üò∫ vs Dogs üê∂ Problem üåü</h2>



<p><h4>Table of Contents</h4> </p>
<p>
1. Problem overview
2. Data processing<br>
   2.1. Import Libraries<br>
   2.2. Preprocessing<br>
        2.2.1. Extract and generate image<br>
        2.2.2. EarlyStopping setting
3. Models Training & Prediction<br>
   3.1. Convolutional Network<br>
   3.2. Convolutional Network with multiple different epoch<br>
   3.3. Stack model with transfer learning and convolutional network<br>
   3.4. Transfer learning Xception model
4. Evaluate the model<br>
   4.1. Generate prediction<br>
   4.2. Confusion Matrix
5. Conclusion
  </p>



<h4> 1. Problem overview </h4>


<p>For an effective approach combining both Deep Neural Networks (DNNs) and Transfer Learning in classifying images of cats and dogs, you can start with a pre-trained DNN model, such as ResNet, VGG, or Inception, which has already learned rich feature representations from a large and diverse dataset. Then, you adapt this model to our specific task (classifying cats and dogs) by fine-tuning some of its layers with our dataset of cat and dog images. This method utilizes the advanced feature extraction capabilities of DNNs and the efficiency of Transfer Learning, enabling our model to achieve high accuracy with less training data and time.

Will Cukierski. (2016). Dogs vs. Cats Redux: Kernels Edition. Kaggle. https://kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition </p>


<p>  <h4> 2. Data processing</h4></p>
<p>   <h4> 2.1. Import Libraries </h4></p>

   <pre><code>
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
from keras.layers import Dense, MaxPool2D, Conv2D, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential


from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications import Xception

from tensorflow.keras.optimizers.schedules import ExponentialDecay
from tensorflow.keras.optimizers import Adam


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
   </pre></code>


   <p><h4>2.2. Preprocessing</h4></p>
   <p><h4> 2.2.1. Extract and generate image</h4></p>
<p>
   <pre><code>
import zipfile
train_zip='../input/dogs-vs-cats-redux-kernels-edition/train.zip'
zip_ref=zipfile.ZipFile(train_zip,'r').extractall('./')

test_zip = '../input/dogs-vs-cats-redux-kernels-edition/test.zip'
zip_ref=zipfile.ZipFile(test_zip,'r').extractall('./')

import os
train_filenames = os.listdir('./train')
test_filenames = os.listdir('./test')

# Create DataFrame with ImageDataGenerator
train = pd.DataFrame(columns=['path', 'label'])
train['path'] = train_filenames
train['label'] = train['path'].str[0:3]

train.label.value_counts().plot.bar() # Balanced Data

width, height = 150, 150
trainDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat', 'dog' ],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='training')

valDatagen = train_datagen.flow_from_dataframe(train, directory = './train', x_col='path', y_col='label', classes=['cat','dog'],
                                           target_size=(width,height), class_mode = 'categorical', batch_size = 16,
                                           subset='validation')


x, y = trainDatagen.next()
x.shape, y.shape

# Display the training data

plt.figure(figsize=(15,15))
for i in range(9):
    img, label = trainDatagen.next()
    plt.subplot(331+i)
    plt.imshow(img[0])
plt.show()
   </pre></code></p>
<img width="663" alt="Screenshot 2024-01-20 at 00 16 42" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/ec5d5021-06a8-400e-aed5-c6cb4984827d">

<p>   <pre><code>
# Test data

test = pd.DataFrame(columns=['path'])
test['path'] = test_filenames
test.head()

test_datagen = ImageDataGenerator(rescale=1/255.0)
width, height = 150, 150
testDatagen = test_datagen.flow_from_dataframe(test, directory = './test', x_col='path', class_mode= None,
                                           target_size=(width,height), batch_size = 16, shuffle=False)

   </pre></code></p>


<h4>  3. Models Training & Prediction </h4>
<h4> 3.1. Convolutional Network </h4>

   <pre><code>
model = models.Sequential()
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))
    
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
 
model.add(layers.Conv2D(128,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())

model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(2,activation='softmax'))

model.compile(loss="categorical_crossentropy",optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['acc'])
 
model.summary()

history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=10, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions = model.predict(testDatagen, batch_size=32, verbose =1)
predictions

submission = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission['label'] = predictions[:,0]
submission.to_csv('submission_cnn_epoch10.csv', index=False)
submission.head()
   </pre></code>

<p>   <pre><code>
history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen), epochs=15, validation_data = valDatagen, validation_steps=len(valDatagen), shuffle=True)

predictions1 = model.predict(testDatagen, batch_size=32, verbose =1)
predictions1

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions1[:,0]
submission1.to_csv('submission_ep15_1.csv', index=False)
submission1.head()
   </pre></code></p>

<p><h4>  3.2. Transfer learning Xception model </h4></p>

<p>   <pre><code>
images_size = 150
batch_size = 32

base_model = Xception(weights='imagenet', include_top=False, input_shape=(images_size, images_size, 3))
for layer in base_model.layers:
    layer.trainable = False

model = models.Sequential([
    base_model,
    
    layers.Flatten(),
    
    layers.Dense(256,activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(2,activation='softmax'),
])

model.summary()

learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,  # Initial learning rate for training
    decay_steps=1000,            # Number of steps before decaying the learning rate
    decay_rate=0.5,              # Rate at which the learning rate decreases
)
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)
model.compile(optimizer=optimizer,
             loss="categorical_crossentropy",
              metrics=['accuracy']
             )
from tensorflow.keras.callbacks import LearningRateScheduler
early_stopping = EarlyStopping(
    min_delta=0.001, # minimium amount of change to count as an improvement
    patience=5, # how many epochs to wait before stopping
    restore_best_weights=True,
)
learning_rate_reduce = ReduceLROnPlateau(
    monitor='val_acc',   # Metric to monitor for changes (usually validation accuracy)
    patience=5,          # Number of epochs with no improvement after which learning rate will be reduced
    verbose=1,           # Verbosity mode (0: silent, 1: update messages)
    factor=0.5,          # Factor by which the learning rate will be reduced (e.g., 0.5 means halving)
    min_lr=0.00001       # Lower bound for the learning rate (it won't go below this value)
)
lr_callback = LearningRateScheduler(learning_rate_schedule)
callback=[ lr_callback , learning_rate_reduce ,early_stopping ]




# ExponentialDecay for the learning rate
learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=1000,
    decay_rate=0.5,
)

# Use this learning rate schedule in the optimizer
optimizer = optimizers.Adam(learning_rate=learning_rate_schedule)

# Compile the model
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

# Callbacks (without LearningRateScheduler)
callbacks = [
    EarlyStopping(
        min_delta=0.001,
        patience=5,
        restore_best_weights=True,
    ),
    # Optionally include ReduceLROnPlateau if you want to use it instead of ExponentialDecay
]

# Fit the model
history = model.fit(
    trainDatagen,
    steps_per_epoch=trainDatagen.samples // batch_size,
    epochs=20,
    validation_data=valDatagen,
    validation_steps=valDatagen.samples // batch_size,
    callbacks=callbacks
)



predictions_xcep = model.predict(testDatagen, batch_size=32, verbose =1)
predictions_xcep


submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_xcep[:,0]
submission1.to_csv('submission_xception.csv', index=False)
submission1.head()
   </pre></code></p>


## 3.3. Stack model with transfer learning and convolutional network


<pre><code>
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import concatenate


# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Custom CNN Model
custom_cnn = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),])

# Feature extraction
# Add GlobalAveragePooling2D to both models
vgg_output = GlobalAveragePooling2D()(vgg16.output)
custom_cnn_output = GlobalAveragePooling2D()(custom_cnn.output)

# Concatenate features
combined = layers.concatenate([vgg_output, custom_cnn_output])


# Additional layers
x = layers.Flatten()(combined)
x = layers.Dense(1024, activation='relu')(x)
#-- output = layers.Dense(10, activation='softmax')(x)  # Adjust number of units based on your problem
output = layers.Dense(2, activation='sigmoid')(x)


# Combined model
model = Model(inputs=[vgg16.input, custom_cnn.input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])# Fit the model


def generate_dual_input(generator):
    for (inputs, labels) in generator:
        yield [inputs, inputs], labels

# Create dual-input generators
train_dual_gen = generate_dual_input(trainDatagen)
val_dual_gen = generate_dual_input(valDatagen)


history = model.fit(
    train_dual_gen,
    steps_per_epoch=len(trainDatagen),
    validation_data=val_dual_gen,
    validation_steps=len(valDatagen),
    epochs=10  # Adjust as needed
)

def generate_dual_input_test(generator):
    for inputs in generator:
        yield [inputs, inputs]


test_dual_gen = generate_dual_input_test(testDatagen)
predictions_stacked = model.predict(test_dual_gen, steps=len(testDatagen), verbose=1)

submission1 = pd.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')
submission1['label'] = predictions_stacked[:,0]
submission1.to_csv('submission_stacked.csv', index=False)
submission1.head()
</pre></code>


<pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()
</pre></code>
<img width="333" alt="Screenshot 2024-01-20 at 15 16 45" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/826f7f67-c6af-4e2f-870c-93d78d5d3648">


<h4> Since we do not have actual label of test dataset on kaggle in order to calculate performance metric like accuracy or precision. </h4>
  In this case, I would like to check it manually by displaying picture along with the predicted label.</h5>

<img width="320" alt="Screenshot 2024-01-20 at 15 18 15" src="https://github.com/trungle14/Image_Classification_Deep_Neural_Network/assets/143222481/478ac336-409b-4d50-a13c-84da1a0ccc57">
<br>
The results show that out of 21 samples out of 12500, we can get 14/21 correct at the cut-off of 80%.
Notice that these results could be relatively sensitive with the chosen cut-off. More importantly, with the small number of sample in the test dataset we can prove that our model does a great job, although the prediction is not really high but always better than random guess.
<br>
<h4>Conclusion</h4><br>

I already tried 4 different models and gained different results accordingly.
<br>
Deep Convolutional network along with batch normalization : 2.4 Kaggle score
Enhance Deep Convolutional network with higher epoch: 5.4 Kaggle score
Stacked model with Transfer learning - VGG16 and Convolutional network: 1.1 Kaggle score
Transfer learning - Xception model: 10.8 Kaggle score
We can see that the Stacked model outperformed the others which is totally make sense when we can combine 2 different kind of models to increase the performacne, due to limitation of time, I only do the stacked model with only 2 models, if I had more time I believe stacked model among transfer learning like ResNet may be able to improve the performance

                      
                      
                    </div>
                  </div>
                </div>
                <div class="col-md-12">
                  <div class="comments text-left padDiv mb-30">
                    <div class="entry-comments">
                      <h6 class="mb-30">4 comments</h6>
                      <ul class="entry-comments-list list-unstyled">
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Sommer Christian</span>
                              <span><a href="#">fev 14, 2018 at 12:48 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                          <ul class="entry-comments-reply list-unstyled">
                            <li>
                              <div class="entry-comments-item">
                                <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                                <div class="entry-comments-body">
                                  <span class="entry-comments-author">Sara Smith</span>
                                  <span><a href="#">fev 14, 2018 at 12:51 pm</a></span>
                                  <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna.</p>
                                  <a class="rep" href="#">Reply</a>
                                </div>
                              </div>
                            </li>
                          </ul>
                        </li>
                        <li>
                          <div class="entry-comments-item">
                            <img src="assets/img/avatar.jpg" class="entry-comments-avatar" alt="">
                            <div class="entry-comments-body">
                              <span class="entry-comments-author">Andrew Lupkin</span>
                              <span><a href="#">fev 14, 2018 at 12:55 pm</a></span>
                              <p class="mb-10">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc quam justo, ullamcorper tincidunt pellentesque in, condimentum ut enim. Aenean at pharetra diam, quis vulputate urna. </p>
                              <a class="rep" href="#">Reply</a>
                            </div>
                          </div>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="col-lg-12">
                  <div class="cmt padDiv">
                    <form id="comment-form" method="post" action="" role="form">
                      <div class="row">
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_name" type="text" name="name" class="form-control" placeholder="Name *" required="required">
                          </div>
                        </div>
                        <div class="col-lg-6">
                          <div class="form-group">
                            <input id="form_email" type="email" name="email" class="form-control" placeholder="email *" required="required">
                          </div>
                        </div>
                        <div class="col-md-12">
                          <div class="form-group">
                            <input id="form_name" type="text" name="website" class="form-control" placeholder="Website">
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <div class="form-group">
                            <textarea id="form_message" name="message" class="form-control" placeholder="Message *" style="height: 200px;" required="required"></textarea>
                          </div>
                        </div>
                        <div class="col-lg-12">
                          <input type="submit" class="btn btn-defeault btn-send" value="Send message">
                        </div>
                      </div>
                    </form>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div><!-- End Blog Single -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <div id="footer" class="text-center">
    <div class="container">
      <div class="socials-media text-center">

        <ul class="list-unstyled">
          <li><a href="#"><i class="bi bi-facebook"></i></a></li>
          <li><a href="#"><i class="bi bi-twitter"></i></a></li>
          <li><a href="#"><i class="bi bi-instagram"></i></a></li>
          <li><a href="#"><i class="bi bi-linkedin"></i></a></li>
        </ul>

      </div>

      <p>&copy; Copyrights Folio. All rights reserved.</p>

      <div class="credits">
        <!--
        All the links in the footer should remain intact.
        You can delete the links only if you purchased the pro version.
        Licensing information: https://bootstrapmade.com/license/
        Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=Folio
      -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>

    </div>
  </div><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
